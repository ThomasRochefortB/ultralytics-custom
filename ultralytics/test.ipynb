{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing KITTI Object detection dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.yaml')  # build a new model from YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.8 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.1 🚀 Python-3.11.7 torch-2.1.2 CPU (Intel Core(TM) i9-9880H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/Users/thomasrochefort/Documents/GitHub/ultralytics-custom/ultralytics/KITTI_dataset/kitti_yolo/data.yaml, epochs=1, time=None, patience=50, batch=16, imgsz=160, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train25, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, reg_gain=0.1, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/thomasrochefort/Documents/GitHub/ultralytics-custom/runs/detect/train25\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3012408 parameters, 3012392 gradients\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/thomasrochefort/Documents/GitHub/ultralytics-custom/ultralytics/KITTI_dataset/kitti_yolo/train... 7481 images, 0 backgrounds, 0 corrupt: 100%|██████████| 7481/7481 [00:26<00:00, 286.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/thomasrochefort/Documents/GitHub/ultralytics-custom/ultralytics/KITTI_dataset/kitti_yolo/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/thomasrochefort/Documents/GitHub/ultralytics-custom/ultralytics/KITTI_dataset/kitti_yolo/test... 0 images, 7518 backgrounds, 0 corrupt: 100%|██████████| 7518/7518 [00:24<00:00, 309.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ No labels found in /Users/thomasrochefort/Documents/GitHub/ultralytics-custom/ultralytics/KITTI_dataset/kitti_yolo/test.cache. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/thomasrochefort/Documents/GitHub/ultralytics-custom/ultralytics/KITTI_dataset/kitti_yolo/test.cache\n",
      "WARNING ⚠️ No labels found in /Users/thomasrochefort/Documents/GitHub/ultralytics-custom/ultralytics/KITTI_dataset/kitti_yolo/test.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n",
      "Plotting labels to /Users/thomasrochefort/Documents/GitHub/ultralytics-custom/runs/detect/train25/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/468 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/thomasrochefort/Documents/GitHub/ultralytics-custom/ultralytics/KITTI_dataset/kitti_yolo/data.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/engine/model.py:390\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/engine/trainer.py:219\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/engine/trainer.py:372\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 372\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_batch_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Warmup\u001b[39;49;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/yolo-custom/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/data/build.py:49\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a sampler that repeats indefinitely.\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/yolo-custom/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/yolo-custom/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/yolo-custom/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/yolo-custom/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/data/base.py:251\u001b[0m, in \u001b[0;36mBaseDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m    250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns transformed label information for given index.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_and_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/data/augment.py:74\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a series of transformations to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 74\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/data/augment.py:74\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a series of transformations to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 74\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/data/augment.py:122\u001b[0m, in \u001b[0;36mBaseMixTransform.__call__\u001b[0;34m(self, labels)\u001b[0m\n\u001b[1;32m    119\u001b[0m labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmix_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mix_labels\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Mosaic or MixUp\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mix_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m labels\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmix_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/data/augment.py:171\u001b[0m, in \u001b[0;36mMosaic._mix_transform\u001b[0;34m(self, labels)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrect_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrect and mosaic are mutually exclusive.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmix_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are no other images for mosaic augment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mosaic3(labels) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mosaic4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mosaic9(labels)\n\u001b[1;32m    172\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/data/augment.py:238\u001b[0m, in \u001b[0;36mMosaic._mosaic4\u001b[0;34m(self, labels)\u001b[0m\n\u001b[1;32m    235\u001b[0m     padw \u001b[38;5;241m=\u001b[39m x1a \u001b[38;5;241m-\u001b[39m x1b\n\u001b[1;32m    236\u001b[0m     padh \u001b[38;5;241m=\u001b[39m y1a \u001b[38;5;241m-\u001b[39m y1b\n\u001b[0;32m--> 238\u001b[0m     labels_patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_patch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     mosaic_labels\u001b[38;5;241m.\u001b[39mappend(labels_patch)\n\u001b[1;32m    240\u001b[0m final_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cat_labels(mosaic_labels)\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/data/augment.py:297\u001b[0m, in \u001b[0;36mMosaic._update_labels\u001b[0;34m(labels, padw, padh)\u001b[0m\n\u001b[1;32m    295\u001b[0m nh, nw \u001b[38;5;241m=\u001b[39m labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    296\u001b[0m labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mconvert_bbox(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxyxy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 297\u001b[0m \u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstances\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39madd_padding(padw, padh)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/utils/instance.py:246\u001b[0m, in \u001b[0;36mInstances.denormalize\u001b[0;34m(self, w, h)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bboxes\u001b[38;5;241m.\u001b[39mmul(scale\u001b[38;5;241m=\u001b[39m(w, h, w, h))\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegments\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m w\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegments[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m h\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeypoints \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "results = model.train(data='/Users/thomasrochefort/Documents/GitHub/ultralytics-custom/ultralytics/KITTI_dataset/kitti_yolo/data.yaml', epochs=1, imgsz=160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n-segreg.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.add_callback(\"on_train_start\", freeze_except_regression_head)\n",
    "\n",
    "model.train(data = '/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/data.yaml', \n",
    "            mosaic = 0.0,\n",
    "            hsv_h= 0.25,  # (float) image HSV-Hue augmentation (fraction)\n",
    "            hsv_s= 0.25,  # (float) image HSV-Saturation augmentation (fraction)\n",
    "            hsv_v= 0.25,  # (float) image HSV-Value augmentation (fraction)\n",
    "            degrees= 45.0,  # (float) image rotation (+/- deg)\n",
    "            translate= 0.4,  # (float) image translation (+/- fraction)\n",
    "            scale= 1.0,  # (float) image scale (+/- gain)\n",
    "            #shear= 10.0,  # (float) image shear (+/- deg)\n",
    "            #perspective= 0.001,  # (float) image perspective (+/- fraction), range 0-0.001\n",
    "            flipud= 0.5,  # (float) image flip up-down (probability)\n",
    "            fliplr= 0.5,\n",
    "            epochs=100, \n",
    "            batch=1,\n",
    "            reg_gain = 1.0,\n",
    "            amp = False,\n",
    "            warmup_epochs=0,\n",
    "            imgsz=640,\n",
    "            workers=12,\n",
    "            lr0=3e-4,\n",
    "            cos_lr = True,\n",
    "            single_cls=True,\n",
    "            rect=True,\n",
    "            overlap_mask=False,\n",
    "            mask_ratio=2,\n",
    "            #freeze=5,\n",
    "            #fraction=0.1,\n",
    "            optimizer = \"AdamW\",\n",
    "            #pretrained=False,\n",
    "            patience=0,\n",
    "            weight_decay=1e-2, \n",
    "            val=True,\n",
    "            resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check models for NaN weights:\n",
    "import torch\n",
    "for k, v in model.model.named_parameters():\n",
    "    if torch.isnan(v).any():\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def get_dropout_rates(model):\n",
    "    dropout_rates = []\n",
    "\n",
    "    # Iterate over all modules (layers) in the model\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Dropout) or \\\n",
    "           isinstance(module, nn.Dropout2d) or \\\n",
    "           isinstance(module, nn.Dropout3d):\n",
    "            dropout_rates.append(module.p)\n",
    "\n",
    "    return dropout_rates\n",
    "\n",
    "\n",
    "get_dropout_rates(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.val(data = '/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/data.yaml',conf=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.val(data = '/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results\n",
    "from PIL import Image\n",
    "\n",
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    im.show()  # show image\n",
    "    im.save('results.jpg')  # save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results\n",
    "from PIL import Image\n",
    "# Load the image\n",
    "image_path = '/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/Topology-optimization-in-a-2D-femur-shaped-design-domain-Left-Classical-topology_W640.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Print the size of the image\n",
    "print(f\"Image size: {image.size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale the image by 2x:\n",
    "\n",
    "# Upscale the image by 2x\n",
    "upscale_factor = 4\n",
    "upscaled_image = image.resize(\n",
    "    (image.width * upscale_factor, image.height * upscale_factor),\n",
    "    resample=Image.BICUBIC\n",
    ")\n",
    "\n",
    "# Print the size of the upscaled image\n",
    "print(f\"Upscaled image size: {upscaled_image.size}\")\n",
    "#show the upscaled image:\n",
    "upscaled_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process the image with your model\n",
    "# results = model(image_path, conf=0.25)\n",
    "results = model(upscaled_image, conf=0.15)\n",
    "\n",
    "for r in results:\n",
    "    im_array = r.plot(boxes=True,labels=False,line_width=1)  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    im.show()  # show image\n",
    "    im.save('results.jpg')  # save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of images path in /home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/opt_large_oct16/train/:\n",
    "import os\n",
    "import glob\n",
    "path = \"/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/valid/\"\n",
    "\n",
    "test_images = glob.glob(path + \"*.png\")\n",
    "test_path = test_images[35].strip('.png')\n",
    "#test_path = '/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/Topology-optimization-in-a-2D-femur-shaped-design-domain-Left-Classical-topology_W640.jpg'\n",
    "results = model(test_path + '.png')\n",
    "# results = model('/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/valid/20231024-094956-993478.png')\n",
    "results = model(upscaled_image, conf=0.25,max_det=10)\n",
    "\n",
    "prediction_tensor = results[0].regression_preds.to('cpu').detach()\n",
    "prediction_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THe labels are stored in the .txt: /home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_opt_final/valid/data_240.txt\n",
    "import numpy as np\n",
    "import torch\n",
    "# Read the file line by line\n",
    "with open(test_path + '.txt', 'r') as file:\n",
    "    data = []\n",
    "    for line in file:\n",
    "        # Split the line based on whitespace and convert to float\n",
    "        numbers = list(map(float, line.split()))\n",
    "        \n",
    "        # Take the first 7 numbers\n",
    "        extracted_numbers = numbers[1:7]\n",
    "        data.append(extracted_numbers)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "data_array = torch.tensor(data)\n",
    "data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Inference code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "class CustomDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(CustomDiceLoss, self).__init__()\n",
    "        self.size_average = size_average\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        # If your model contains a sigmoid or equivalent activation layer, comment this line\n",
    "        #inputs = F.sigmoid(inputs)       \n",
    "      \n",
    "        # Check if the input tensors are of expected shape\n",
    "        if inputs.shape != targets.shape:\n",
    "            raise ValueError(\"Shape mismatch: inputs and targets must have the same shape\")\n",
    "\n",
    "        # Compute Dice loss for each sample in the batch\n",
    "        dice_loss_values = []\n",
    "        for input_sample, target_sample in zip(inputs, targets):\n",
    "            \n",
    "            # Flatten tensors for each sample\n",
    "            input_sample = input_sample.view(-1)\n",
    "            target_sample = target_sample.view(-1)\n",
    "\n",
    "            intersection = (input_sample * target_sample).sum()\n",
    "            dice = (2. * intersection + smooth) / (input_sample.sum() + target_sample.sum() + smooth)\n",
    "            \n",
    "            dice_loss_values.append(1 - dice)\n",
    "\n",
    "        # Convert list of Dice loss values to a tensor\n",
    "        dice_loss_values = torch.stack(dice_loss_values)\n",
    "\n",
    "        # If you want the average loss over the batch to be returned\n",
    "        if self.size_average:\n",
    "            return dice_loss_values.mean()\n",
    "        else:\n",
    "            # If you want individual losses for each sample in the batch\n",
    "            return dice_loss_values\n",
    "\n",
    "def smooth_heaviside(phi, alpha, epsilon):\n",
    "    # Scale and shift phi for the sigmoid function\n",
    "    scaled_phi = (phi - alpha) / epsilon\n",
    "    \n",
    "    # Apply the sigmoid function\n",
    "    H = torch.sigmoid(scaled_phi)\n",
    "\n",
    "    return H\n",
    "def calc_Phi(variable, LSgrid):\n",
    "    device = variable.device  # Get the device of the variable\n",
    "\n",
    "    x0 = variable[0]\n",
    "    y0 = variable[1]\n",
    "    L = variable[2]\n",
    "    t1 = variable[3]\n",
    "    t2 = variable[4]\n",
    "    angle = variable[5]\n",
    "\n",
    "    # Rotation\n",
    "    st = torch.sin(angle)\n",
    "    ct = torch.cos(angle)\n",
    "    x1 = ct * (LSgrid[0][:, None].to(device) - x0) + st * (LSgrid[1][:, None].to(device) - y0) \n",
    "    y1 = -st * (LSgrid[0][:, None].to(device) - x0) + ct * (LSgrid[1][:, None].to(device) - y0)\n",
    "\n",
    "    # Regularized hyperellipse equation\n",
    "    a = L / 2  # Semi-major axis\n",
    "    b = (t1 + t2) / 2  # Semi-minor axis\n",
    "    small_constant = 1e-9  # To avoid division by zero\n",
    "    temp = ((x1 / (a + small_constant))**6) + ((y1 / (b + small_constant))**6)\n",
    "\n",
    "    # # Ensuring the hyperellipse shape\n",
    "    allPhi = 1 - (temp + small_constant)**(1/6)\n",
    "\n",
    "    # # Call Heaviside function with allPhi\n",
    "    alpha = torch.tensor(1e-9, device=device, dtype=torch.float32)\n",
    "    epsilon = torch.tensor(0.02, device=device, dtype=torch.float32)\n",
    "    H_phi = smooth_heaviside(allPhi, alpha, epsilon)\n",
    "    return allPhi, H_phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "\n",
    "norm = TwoSlopeNorm(vmin=-10, vcenter=0, vmax=10)\n",
    "# Load the input image\n",
    "input_image_path = test_path + '.png'\n",
    "input_image = Image.open(input_image_path)\n",
    "input_image = upscaled_image\n",
    "#I want to create a numpy array of the grayscale input image where black is 1 and white is 0:\n",
    "input_image_array = np.array(input_image.convert('L'))\n",
    "# input_image_array is of shape (480,640) and pred_H_resized is of shape (1,1,160,160):\n",
    "# I want to calculate the dice loss between the two:\n",
    "# I first need to resize the input_image_array to 160,160 using  F.interpolate\n",
    "input_image_array_tensor = torch.tensor(input_image_array)\n",
    "\n",
    "resized_input_image_array_tensor = F.interpolate(input_image_array_tensor.unsqueeze(0).unsqueeze(0), size=torch.Size([640,640]), mode='nearest')\n",
    "\n",
    "# Normalize the resized_input_image_array_tensor:\n",
    "resized_input_image_array_tensor = resized_input_image_array_tensor / 255.0\n",
    "\n",
    "#Now the input_image has pixel values of 1.0 for white and 0.0 for black. I need to inverse that:\n",
    "resized_input_image_array_tensor = 1.0 - resized_input_image_array_tensor\n",
    "\n",
    "\n",
    "#I need to flip upside down the resized_input_image_array_tensor:\n",
    "resized_input_image_array_tensor = torch.flip(resized_input_image_array_tensor, [2])\n",
    "# Get the segmentation result\n",
    "for r in results:\n",
    "    im_array = r.plot(boxes=True, labels=False, line_width=1)\n",
    "    seg_result = Image.fromarray(im_array[..., ::-1])\n",
    "\n",
    "\n",
    "\n",
    "DW = 1.0\n",
    "DH = 1.0\n",
    "\n",
    "\n",
    "nelx = int(400 * DW)\n",
    "nely = int(400 * DH)\n",
    "\n",
    "x, y = torch.meshgrid(torch.linspace(0, DW, nelx+1), torch.linspace(0, DH, nely+1))\n",
    "LSgrid = torch.stack((y.flatten(), x.flatten()), dim=0)\n",
    "\n",
    "#xmax = torch.tensor([DW, DH, np.sqrt(DW**2 + DH**2), 0.05 * min(DW, DH), 0.05 * min(DW, DH), np.pi])\n",
    "xmax = torch.tensor([1.0, 1.0, 1.0, 1.0, 0.2, 0.2])\n",
    "\n",
    "xmin = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.01, 0.01])\n",
    "\n",
    "\n",
    "xmax_preds = xmax.unsqueeze(0).expand(prediction_tensor.shape[0],-1) \n",
    "xmin_preds = xmin.unsqueeze(0).expand(prediction_tensor.shape[0],-1)\n",
    "\n",
    "xmax = xmax.unsqueeze(0).expand(8, -1)  \n",
    "xmin = xmin.unsqueeze(0).expand(8, -1) \n",
    "unnormalized_preds = prediction_tensor * (xmax_preds - xmin_preds) + xmin_preds\n",
    "# # # The design variables are infered from the two endpoints and the two thicknesses:\n",
    "x_center = (unnormalized_preds[:, 0] + unnormalized_preds[:, 2]) / 2\n",
    "y_center = (unnormalized_preds[:, 1] + unnormalized_preds[:, 3]) / 2\n",
    "\n",
    "L = torch.sqrt((unnormalized_preds[:, 0] - unnormalized_preds[:, 2])**2 + \n",
    "            (unnormalized_preds[:, 1] - unnormalized_preds[:, 3])**2)\n",
    "\n",
    "L = L+1e-4\n",
    "t_1 = unnormalized_preds[:, 4]\n",
    "t_2 = unnormalized_preds[:, 5]\n",
    "\n",
    "epsilon = 1e-10\n",
    "y_diff = unnormalized_preds[:, 3] - unnormalized_preds[:, 1] + epsilon\n",
    "x_diff = unnormalized_preds[:, 2] - unnormalized_preds[:, 0] + epsilon\n",
    "theta = torch.atan2(y_diff, x_diff)\n",
    "formatted_variables = torch.cat((x_center.unsqueeze(1), \n",
    "                    y_center.unsqueeze(1), \n",
    "                    L.unsqueeze(1), \n",
    "                    t_1.unsqueeze(1), \n",
    "                    t_2.unsqueeze(1), \n",
    "                    theta.unsqueeze(1)), dim=1)\n",
    "\n",
    "pred_Phi,pred_H = calc_Phi(formatted_variables.T,LSgrid)\n",
    "\n",
    "\n",
    "sum_pred_H = torch.sum(pred_H, dim=1)\n",
    "sum_pred_H= torch.reshape(sum_pred_H,(1,1,nely+1,nelx+1))\n",
    "\n",
    "# # Rearrange H_phi to the shape ([batch_size, channels, height, width])\n",
    "# # Use interpolate to resize\n",
    "pred_H_resized = F.interpolate(sum_pred_H, size=torch.Size([640,640]), mode='nearest')\n",
    "\n",
    "diceloss = CustomDiceLoss()\n",
    "pred_H_resized_flipped = torch.flip(pred_H_resized, [2])\n",
    "\n",
    "#threshold both the prediction and the label with 0.5:\n",
    "pred_H_resized_flipped[pred_H_resized_flipped > 0.5] = 1\n",
    "pred_H_resized_flipped[pred_H_resized_flipped <= 0.5] = 0\n",
    "# Calculate the dice loss:\n",
    "dice_loss = diceloss(pred_H_resized_flipped, resized_input_image_array_tensor)\n",
    "\n",
    "\n",
    "# Create a combined 2x2 plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12)) # 2x2 subplot\n",
    "\n",
    "# Top-left: Input image\n",
    "axes[0, 0].imshow(resized_input_image_array_tensor.squeeze(),origin='lower', cmap='gray_r')\n",
    "axes[0, 0].set_title('Input Image')\n",
    "axes[0, 0].axis('on')\n",
    "\n",
    "# Top-right: Segmentation Result\n",
    "axes[0, 1].imshow(seg_result)\n",
    "axes[0, 1].set_title('Segmentation Result')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# # Bottom-right: pred_Phi contour\n",
    "render_colors1 = ['yellow', 'g', 'r', 'c', 'm', 'y', 'black', 'orange', 'pink', 'cyan', 'slategrey', 'wheat', 'purple', 'mediumturquoise', 'darkviolet', 'orangered']\n",
    "for i, color in zip(range(0, pred_Phi.shape[1]), render_colors1*10):\n",
    "    axes[1, 1].contourf(np.flipud(pred_Phi[:, i].reshape((nely+1, nelx+1))), [-0.1,0,1], colors=color)\n",
    "axes[1, 1].set_title('Prediction contours')\n",
    "\n",
    "# Bottom-left: Prediction H\n",
    "axes[1, 0].imshow(pred_H_resized_flipped.squeeze().detach().numpy(), origin='lower', cmap='gray_r')\n",
    "axes[1, 0].set_title('Prediction Projection')\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.01)  # Adjust hspace to reduce vertical space\n",
    "\n",
    "plt.figtext(0.5, 0.05, f'Dice Loss: {dice_loss.item():.4f}', ha='center', fontsize=16)\n",
    "\n",
    "# Save the combined plot\n",
    "fig.savefig('combined_plots.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_image_array is of shape (480,640) and pred_H_resized is of shape (1,1,160,160):\n",
    "# I want to calculate the dice loss between the two:\n",
    "# I first need to resize the input_image_array to 160,160 using  F.interpolate\n",
    "input_image_array_tensor = torch.tensor(input_image_array)\n",
    "\n",
    "\n",
    "resized_input_image_array_tensor = F.interpolate(input_image_array_tensor.unsqueeze(0).unsqueeze(0), size=torch.Size([160,160]), mode='nearest')\n",
    "\n",
    "# Normalize the resized_input_image_array_tensor:\n",
    "resized_input_image_array_tensor = resized_input_image_array_tensor / 255.0\n",
    "\n",
    "#Now the input_image has pixel values of 1.0 for white and 0.0 for black. I need to inverse that:\n",
    "resized_input_image_array_tensor = 1.0 - resized_input_image_array_tensor\n",
    "\n",
    "\n",
    "\n",
    "#I need to flip upside down the resized_input_image_array_tensor:\n",
    "resized_input_image_array_tensor = torch.flip(resized_input_image_array_tensor, [2])\n",
    "# Calculate the dice loss:\n",
    "dice_loss = diceloss(pred_H_resized_flipped, resized_input_image_array_tensor)\n",
    "\n",
    "dice_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Heaviside(phi, alpha, epsilon):\n",
    "    device = phi.device  # Get the device of phi\n",
    "\n",
    "    # For values outside of [-epsilon, epsilon]\n",
    "    H_positive = torch.ones_like(phi, device=device) \n",
    "    H_negative = alpha * torch.ones_like(phi, device=device)\n",
    "\n",
    "    # For values inside [-epsilon, epsilon]\n",
    "    default = 3 * (1 - alpha) / 4 * (phi / epsilon - phi**3 / (3 * epsilon**3)) + (1 + alpha) / 2\n",
    "\n",
    "    # Construct Heavisidve using conditions\n",
    "    H = torch.where(phi > epsilon, H_positive, torch.where(phi < -epsilon, H_negative, default))\n",
    "\n",
    "    return H\n",
    "\n",
    "\n",
    "def smooth_heaviside(phi, alpha, epsilon):\n",
    "    # Scale and shift phi for the sigmoid function\n",
    "    scaled_phi = (phi - alpha) / epsilon\n",
    "    \n",
    "    # Apply the sigmoid function\n",
    "    H = torch.sigmoid(scaled_phi)\n",
    "\n",
    "    return H\n",
    "\n",
    "# def calc_Phi(variable, LSgrid):\n",
    "#     device = variable.device  # Get the device of variable\n",
    "#     alpha = torch.tensor(1e-9, device=device, dtype=torch.float32)\n",
    "#     epsilon = torch.tensor(0.01, device=device, dtype=torch.float32)\n",
    "\n",
    "\n",
    "#     x0 = variable[0]\n",
    "#     y0 = variable[1]\n",
    "#     L = variable[2]\n",
    "#     t1 = variable[3]\n",
    "#     t2 = variable[4]\n",
    "#     angle = variable[5]\n",
    "\n",
    "#     st = torch.sin(angle)\n",
    "#     ct = torch.cos(angle)\n",
    "\n",
    "#     x1 = ct * (LSgrid[0][:, None].to(device) - x0) + st * (LSgrid[1][:, None].to(device) - y0) \n",
    "#     y1 = -st * (LSgrid[0][:, None].to(device) - x0) + ct * (LSgrid[1][:, None].to(device) - y0) \n",
    "#     small_constant = 1e-09  # You can adjust this value\n",
    "#     l = (t1 + t2) / 2 + (t2 - t1) / 2 / L * x1\n",
    "#     temp = ((x1)**6) / ((L**6)) + ((y1)**6) / ((l**6))\n",
    "#     allPhi = 1 - (temp+small_constant)**(1/6)\n",
    "    \n",
    "#     # # Call Heaviside function with allPhi, alpha, and epsilon\n",
    "#     H_phi = smooth_heaviside(allPhi, alpha, epsilon)\n",
    "\n",
    "#     # return allPhi\n",
    "#     return  allPhi, H_phi\n",
    "\n",
    "def calc_Phi(variable, LSgrid):\n",
    "    device = variable.device  # Get the device of the variable\n",
    "\n",
    "    x0 = variable[0]\n",
    "    y0 = variable[1]\n",
    "    L = variable[2]\n",
    "    t1 = variable[3]\n",
    "    t2 = variable[4]\n",
    "    angle = variable[5]\n",
    "\n",
    "    # Rotation\n",
    "    st = torch.sin(angle)\n",
    "    ct = torch.cos(angle)\n",
    "    x1 = ct * (LSgrid[0][:, None].to(device) - x0) + st * (LSgrid[1][:, None].to(device) - y0) \n",
    "    y1 = -st * (LSgrid[0][:, None].to(device) - x0) + ct * (LSgrid[1][:, None].to(device) - y0)\n",
    "\n",
    "    # Regularized hyperellipse equation\n",
    "    a = L / 2  # Semi-major axis\n",
    "    b = (t1 + t2) / 2  # Semi-minor axis\n",
    "    small_constant = 1e-9  # To avoid division by zero\n",
    "    temp = ((x1 / (a + small_constant))**6) + ((y1 / (b + small_constant))**6)\n",
    "\n",
    "    # # Ensuring the hyperellipse shape\n",
    "    allPhi = 1 - (temp + small_constant)**(1/6)\n",
    "\n",
    "    # # Call Heaviside function with allPhi\n",
    "    alpha = torch.tensor(1e-9, device=device, dtype=torch.float32)\n",
    "    epsilon = torch.tensor(0.01, device=device, dtype=torch.float32)\n",
    "    H_phi = smooth_heaviside(allPhi, alpha, epsilon)\n",
    "    return allPhi, H_phi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import gradcheck\n",
    "import numpy as np\n",
    "# Your calc_Phi function here\n",
    "\n",
    "# Preparing the grid as in your example\n",
    "DW = 1.0\n",
    "DH = 1.0\n",
    "nelx = int(400 * DW)\n",
    "nely = int(400 * DH)\n",
    "x, y = torch.meshgrid(torch.linspace(0, DW, nelx+1), torch.linspace(0, DH, nely+1), indexing='xy')\n",
    "LSgrid = torch.stack((y.flatten(), x.flatten()), dim=0).to(torch.float64)\n",
    "\n",
    "# Ensure the test_tensor and p require gradients\n",
    "test_tensor = torch.tensor([0.5, 0.5, 1.0, 1.0, 0.0, 0.0], requires_grad=True,dtype=torch.float64).unsqueeze(0)\n",
    "\n",
    "\n",
    "# xmax = torch.tensor([1.0, 1.0, 0.75, 0.2, 0.2, np.pi])\n",
    "\n",
    "# xmin = torch.tensor([0.0, 0.0, 0.01, 0.01, 0.00, 0.0])\n",
    "\n",
    "xmax = torch.tensor([1.0, 1.0, 1.0, 1.0, 0.2, 0.2])\n",
    "\n",
    "xmin = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.01, 0.01])\n",
    "\n",
    "unnormalized_preds = test_tensor * (xmax - xmin) + xmin\n",
    "# The design variables are infered from the two endpoints and the two thicknesses:\n",
    "x_center = (unnormalized_preds[:, 0] + unnormalized_preds[:, 2]) / 2\n",
    "y_center = (unnormalized_preds[:, 1] + unnormalized_preds[:, 3]) / 2\n",
    "\n",
    "def safe_sqrt(x, eps=1e-6):\n",
    "    return torch.sqrt(x + eps)\n",
    "\n",
    "L = safe_sqrt((unnormalized_preds[:, 0] - unnormalized_preds[:, 2])**2 + \n",
    "            (unnormalized_preds[:, 1] - unnormalized_preds[:, 3])**2)\n",
    "\n",
    "# gradcheck_result = gradcheck(safe_sqrt, ((unnormalized_preds[:, 0] - unnormalized_preds[:, 2])**2 + \n",
    "#             (unnormalized_preds[:, 1] - unnormalized_preds[:, 3])**2))\n",
    "# print(\"Gradcheck passed:\", gradcheck_result)\n",
    "\n",
    "L = L+1e-4\n",
    "t_1 = unnormalized_preds[:, 4]\n",
    "t_2 = unnormalized_preds[:, 5]\n",
    "\n",
    "y_diff = unnormalized_preds[:, 3] - unnormalized_preds[:, 1] \n",
    "x_diff = unnormalized_preds[:, 2] - unnormalized_preds[:, 0] \n",
    "theta = torch.atan2(y_diff, x_diff)\n",
    "\n",
    "formatted_variables = torch.cat((x_center.unsqueeze(1), \n",
    "                    y_center.unsqueeze(1), \n",
    "                    L.unsqueeze(1), \n",
    "                    t_1.unsqueeze(1), \n",
    "                    t_2.unsqueeze(1), \n",
    "                    theta.unsqueeze(1)), dim=1)\n",
    "# # # # # # # Call gradcheck\n",
    "# gradcheck_result = gradcheck(calc_Phi, (unnormalized_preds.T, LSgrid))\n",
    "\n",
    "# print(\"Gradcheck passed:\", gradcheck_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(unnormalized_preds)\n",
    "# pred_Phi, H_phi = calc_Phi(unnormalized_preds.T, LSgrid)\n",
    "pred_phi, H_phi = calc_Phi(formatted_variables.T, LSgrid)\n",
    "\n",
    "H_phi = H_phi.detach()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Calculate the sigmoid function of H_phi:\n",
    "#sigmoid = 1/(1+np.exp(-H_phi))\n",
    "# Plot the sigmoid function\n",
    "plt.imshow(H_phi.detach().reshape((nely+1, nelx+1)), cmap='viridis', origin='lower')\n",
    "plt.colorbar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "DW = 1.0\n",
    "DH = 1.0\n",
    "\n",
    "test_tensor = torch.tensor([0.5, 0.5, 0.5, 1.0, 1.0, 1.0]).unsqueeze(0)\n",
    "nelx = int(200 * DW)\n",
    "nely = int(200 * DH)\n",
    "\n",
    "x, y = torch.meshgrid(torch.linspace(0, DW, nelx+1), torch.linspace(0, DH, nely+1))\n",
    "LSgrid = torch.stack((y.flatten(), x.flatten()), dim=0)\n",
    "\n",
    "#xmax = torch.tensor([DW, DH, np.sqrt(DW**2 + DH**2), 0.05 * min(DW, DH), 0.05 * min(DW, DH), np.pi])\n",
    "xmax = torch.tensor([1.0, 1.0, 0.75, 0.05, 0.05, np.pi])\n",
    "\n",
    "xmin = torch.tensor([0.0, 0.0, 0.001, 0.0, 0.0, 0.0])\n",
    "\n",
    "\n",
    "\n",
    "xmax_preds = xmax.unsqueeze(0).expand(test_tensor.shape[0],-1) \n",
    "xmin_preds = xmin.unsqueeze(0).expand(test_tensor.shape[0],-1)\n",
    "\n",
    "xmax = xmax.unsqueeze(0).expand(8, -1)  \n",
    "xmin = xmin.unsqueeze(0).expand(8, -1) \n",
    "\n",
    "unnormalized_preds = test_tensor * (xmax_preds - xmin_preds) + xmin_preds\n",
    "\n",
    "\n",
    "pred_Phi,pred_H = calc_Phi(unnormalized_preds.T,LSgrid,6,epsilon=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(pred_H.reshape(201,201).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to scale pred_Phi[:,0] to [0,1] and then plot it:\n",
    "normalized = (pred_Phi[:,0] - pred_Phi[:,0].min()) / (pred_Phi[:,0].max() - pred_Phi[:,0].min())\n",
    "\n",
    "plt.imshow((normalized>0.9).reshape((nely+1, nelx+1)))\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(normalized.reshape(201,201), pred_H.reshape(201,201))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming pred_Phi is defined somewhere in your code\n",
    "# normalized = (pred_Phi[:,2] - pred_Phi[:,2].min()) / (pred_Phi[:,2].max() - pred_Phi[:,2].min())\n",
    "\n",
    "# Create a meshgrid for plotting\n",
    "x = np.linspace(0, 1, nelx+1)\n",
    "y = np.linspace(0, 1, nely+1)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Create a figure and 3D axis\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the surface\n",
    "surf = ax.plot_surface(X, Y, np.minimum(pred_Phi[:,1],0.0).reshape((nely+1, nelx+1)), cmap='viridis')\n",
    "\n",
    "# Add colorbar\n",
    "fig.colorbar(surf)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you've defined and normalized your data as before...\n",
    "\n",
    "\n",
    "\n",
    "# Create the 3D surface plot\n",
    "fig = go.Figure(data=[go.Surface(z=np.minimum(pred_Phi[:,2],0.0).reshape((nely+1, nelx+1)), x=X, y=Y, colorscale='viridis')])\n",
    "\n",
    "fig.update_layout(title='3D Surface Plot', scene=dict(zaxis=dict(range=[-10,1])),height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming pred_H_resized_flipped and label_H_resized are thresholded to contain values 0 or 1.\n",
    "\n",
    "# 1. Compute the intersection\n",
    "intersection = pred_H_resized_flipped * label_H_resized\n",
    "\n",
    "# 2. Plot the original images and their intersection\n",
    "\n",
    "# Create a combined 3x1 plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 12)) # 3x1 subplot to account for colorbars\n",
    "\n",
    "# Left: label_H_resized\n",
    "im0 = axes[0].imshow(label_H_resized[0,0,:,:], origin='lower')\n",
    "axes[0].set_title('Ground Truth')\n",
    "#fig.colorbar(im0, ax=axes[0])\n",
    "\n",
    "# Middle: pred_H_resized_flipped\n",
    "im1 = axes[1].imshow(pred_H_resized_flipped[0,0,:,:], origin='lower')\n",
    "axes[1].set_title('Prediction')\n",
    "#fig.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# Right: Intersection\n",
    "im2 = axes[2].imshow(intersection[0,0,:,:], origin='lower')\n",
    "axes[2].set_title('Intersection')\n",
    "#fig.colorbar(im2, ax=axes[2])\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the input image\n",
    "input_image_path = test_path + '.png'\n",
    "input_image = Image.open(input_image_path)\n",
    "\n",
    "# Get the segmentation result\n",
    "results = model(input_image_path, conf=0.25)\n",
    "for r in results:\n",
    "    im_array = r.plot(boxes=True, labels=False, line_width=1)\n",
    "    seg_result = Image.fromarray(im_array[..., ::-1])\n",
    "\n",
    "# Create a combined 1x2 plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # 1x2 subplot\n",
    "\n",
    "# Left: Input image\n",
    "axes[0].imshow(input_image)\n",
    "axes[0].set_title('Input Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Right: Segmentation Result\n",
    "axes[1].imshow(seg_result)\n",
    "axes[1].set_title('Segmentation Result')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customyolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
