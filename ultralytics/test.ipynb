{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n-segreg.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.215 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080, 10018MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/runs/segment/train437/weights/last.pt, data=/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/data.yaml, epochs=100, patience=0, batch=1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=12, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=True, rect=True, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, overlap_mask=False, mask_ratio=2, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0003, lrf=0.01, momentum=0.937, weight_decay=0.01, warmup_epochs=0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, reg_gain=1.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.25, hsv_s=0.25, hsv_v=0.25, degrees=45.0, translate=0.4, scale=1.0, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train437\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   2439877  ultralytics.nn.modules.head.ExtendedSegment  [1, 32, 256, [64, 128, 256]]  \n",
      "YOLOv8n-segreg summary: 280 layers, 4699413 parameters, 4699397 gradients\n",
      "\n",
      "Transferred 441/441 items from pretrained weights\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# model.add_callback(\"on_train_start\", freeze_except_regression_head)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(data \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/data.yaml\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m             mosaic \u001b[39m=\u001b[39;49m \u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m             hsv_h\u001b[39m=\u001b[39;49m \u001b[39m0.25\u001b[39;49m,  \u001b[39m# (float) image HSV-Hue augmentation (fraction)\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m             hsv_s\u001b[39m=\u001b[39;49m \u001b[39m0.25\u001b[39;49m,  \u001b[39m# (float) image HSV-Saturation augmentation (fraction)\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m             hsv_v\u001b[39m=\u001b[39;49m \u001b[39m0.25\u001b[39;49m,  \u001b[39m# (float) image HSV-Value augmentation (fraction)\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m             degrees\u001b[39m=\u001b[39;49m \u001b[39m45.0\u001b[39;49m,  \u001b[39m# (float) image rotation (+/- deg)\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m             translate\u001b[39m=\u001b[39;49m \u001b[39m0.4\u001b[39;49m,  \u001b[39m# (float) image translation (+/- fraction)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m             scale\u001b[39m=\u001b[39;49m \u001b[39m1.0\u001b[39;49m,  \u001b[39m# (float) image scale (+/- gain)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m             \u001b[39m#shear= 10.0,  # (float) image shear (+/- deg)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m             \u001b[39m#perspective= 0.001,  # (float) image perspective (+/- fraction), range 0-0.001\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m             flipud\u001b[39m=\u001b[39;49m \u001b[39m0.5\u001b[39;49m,  \u001b[39m# (float) image flip up-down (probability)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m             fliplr\u001b[39m=\u001b[39;49m \u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m             batch\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m             reg_gain \u001b[39m=\u001b[39;49m \u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m             amp \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m             warmup_epochs\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m             imgsz\u001b[39m=\u001b[39;49m\u001b[39m640\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m             workers\u001b[39m=\u001b[39;49m\u001b[39m12\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m             lr0\u001b[39m=\u001b[39;49m\u001b[39m3e-4\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m             cos_lr \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m             single_cls\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m             rect\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m             overlap_mask\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m             mask_ratio\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m             \u001b[39m#freeze=5,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m             \u001b[39m#fraction=0.1,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m             optimizer \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mAdamW\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m             \u001b[39m#pretrained=False,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m             patience\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m             weight_decay\u001b[39m=\u001b[39;49m\u001b[39m1e-2\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m             val\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bholodeck/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m             resume\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/engine/model.py:341\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[1;32m    340\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    342\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/engine/trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[1;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/engine/trainer.py:306\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m world_size \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    305\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_ddp(world_size)\n\u001b[0;32m--> 306\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_train(world_size)\n\u001b[1;32m    308\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_time \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/engine/trainer.py:229\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks(\u001b[39m'\u001b[39m\u001b[39mon_pretrain_routine_start\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    228\u001b[0m ckpt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup_model()\n\u001b[0;32m--> 229\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    230\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_model_attributes()\n\u001b[1;32m    232\u001b[0m \u001b[39m# Freeze layers\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/customyolo/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/Documents/GitHub/ultralytics-custom/ultralytics/nn/tasks.py:180\u001b[0m, in \u001b[0;36mBaseModel._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    171\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m    Applies a function to all the tensors in the model that are not parameters or registered buffers.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39m        A model that is a Detect() object.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    181\u001b[0m     m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]  \u001b[39m# Detect()\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(m, (Detect, Segment)):\n",
      "File \u001b[0;32m~/anaconda3/envs/customyolo/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/customyolo/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/customyolo/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/customyolo/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/customyolo/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# model.add_callback(\"on_train_start\", freeze_except_regression_head)\n",
    "\n",
    "model.train(data = '/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/data.yaml', \n",
    "            mosaic = 0.0,\n",
    "            hsv_h= 0.25,  # (float) image HSV-Hue augmentation (fraction)\n",
    "            hsv_s= 0.25,  # (float) image HSV-Saturation augmentation (fraction)\n",
    "            hsv_v= 0.25,  # (float) image HSV-Value augmentation (fraction)\n",
    "            degrees= 45.0,  # (float) image rotation (+/- deg)\n",
    "            translate= 0.4,  # (float) image translation (+/- fraction)\n",
    "            scale= 1.0,  # (float) image scale (+/- gain)\n",
    "            #shear= 10.0,  # (float) image shear (+/- deg)\n",
    "            #perspective= 0.001,  # (float) image perspective (+/- fraction), range 0-0.001\n",
    "            flipud= 0.5,  # (float) image flip up-down (probability)\n",
    "            fliplr= 0.5,\n",
    "            epochs=100, \n",
    "            batch=1,\n",
    "            reg_gain = 1.0,\n",
    "            amp = False,\n",
    "            warmup_epochs=0,\n",
    "            imgsz=640,\n",
    "            workers=12,\n",
    "            lr0=3e-4,\n",
    "            cos_lr = True,\n",
    "            single_cls=True,\n",
    "            rect=True,\n",
    "            overlap_mask=False,\n",
    "            mask_ratio=2,\n",
    "            #freeze=5,\n",
    "            #fraction=0.1,\n",
    "            optimizer = \"AdamW\",\n",
    "            #pretrained=False,\n",
    "            patience=0,\n",
    "            weight_decay=1e-2, \n",
    "            val=True,\n",
    "            resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check models for NaN weights:\n",
    "import torch\n",
    "for k, v in model.model.named_parameters():\n",
    "    if torch.isnan(v).any():\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def get_dropout_rates(model):\n",
    "    dropout_rates = []\n",
    "\n",
    "    # Iterate over all modules (layers) in the model\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Dropout) or \\\n",
    "           isinstance(module, nn.Dropout2d) or \\\n",
    "           isinstance(module, nn.Dropout3d):\n",
    "            dropout_rates.append(module.p)\n",
    "\n",
    "    return dropout_rates\n",
    "\n",
    "\n",
    "get_dropout_rates(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.val(data = '/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/data.yaml',conf=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.val(data = '/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results\n",
    "from PIL import Image\n",
    "\n",
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    im.show()  # show image\n",
    "    im.save('results.jpg')  # save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results\n",
    "from PIL import Image\n",
    "# Load the image\n",
    "image_path = '/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/Topology-optimization-in-a-2D-femur-shaped-design-domain-Left-Classical-topology_W640.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Print the size of the image\n",
    "print(f\"Image size: {image.size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale the image by 2x:\n",
    "\n",
    "# Upscale the image by 2x\n",
    "upscale_factor = 4\n",
    "upscaled_image = image.resize(\n",
    "    (image.width * upscale_factor, image.height * upscale_factor),\n",
    "    resample=Image.BICUBIC\n",
    ")\n",
    "\n",
    "# Print the size of the upscaled image\n",
    "print(f\"Upscaled image size: {upscaled_image.size}\")\n",
    "#show the upscaled image:\n",
    "upscaled_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process the image with your model\n",
    "# results = model(image_path, conf=0.25)\n",
    "results = model(upscaled_image, conf=0.15)\n",
    "\n",
    "for r in results:\n",
    "    im_array = r.plot(boxes=True,labels=False,line_width=1)  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    im.show()  # show image\n",
    "    im.save('results.jpg')  # save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of images path in /home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/opt_large_oct16/train/:\n",
    "import os\n",
    "import glob\n",
    "path = \"/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/valid/\"\n",
    "\n",
    "test_images = glob.glob(path + \"*.png\")\n",
    "test_path = test_images[35].strip('.png')\n",
    "#test_path = '/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/Topology-optimization-in-a-2D-femur-shaped-design-domain-Left-Classical-topology_W640.jpg'\n",
    "results = model(test_path + '.png')\n",
    "# results = model('/home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_dataset_nov10/valid/20231024-094956-993478.png')\n",
    "results = model(upscaled_image, conf=0.25,max_det=10)\n",
    "\n",
    "prediction_tensor = results[0].regression_preds.to('cpu').detach()\n",
    "prediction_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THe labels are stored in the .txt: /home/thomas/Documents/GitHub/ultralytics-custom/ultralytics/yolo_opt_final/valid/data_240.txt\n",
    "import numpy as np\n",
    "import torch\n",
    "# Read the file line by line\n",
    "with open(test_path + '.txt', 'r') as file:\n",
    "    data = []\n",
    "    for line in file:\n",
    "        # Split the line based on whitespace and convert to float\n",
    "        numbers = list(map(float, line.split()))\n",
    "        \n",
    "        # Take the first 7 numbers\n",
    "        extracted_numbers = numbers[1:7]\n",
    "        data.append(extracted_numbers)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "data_array = torch.tensor(data)\n",
    "data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Inference code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "class CustomDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(CustomDiceLoss, self).__init__()\n",
    "        self.size_average = size_average\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        # If your model contains a sigmoid or equivalent activation layer, comment this line\n",
    "        #inputs = F.sigmoid(inputs)       \n",
    "      \n",
    "        # Check if the input tensors are of expected shape\n",
    "        if inputs.shape != targets.shape:\n",
    "            raise ValueError(\"Shape mismatch: inputs and targets must have the same shape\")\n",
    "\n",
    "        # Compute Dice loss for each sample in the batch\n",
    "        dice_loss_values = []\n",
    "        for input_sample, target_sample in zip(inputs, targets):\n",
    "            \n",
    "            # Flatten tensors for each sample\n",
    "            input_sample = input_sample.view(-1)\n",
    "            target_sample = target_sample.view(-1)\n",
    "\n",
    "            intersection = (input_sample * target_sample).sum()\n",
    "            dice = (2. * intersection + smooth) / (input_sample.sum() + target_sample.sum() + smooth)\n",
    "            \n",
    "            dice_loss_values.append(1 - dice)\n",
    "\n",
    "        # Convert list of Dice loss values to a tensor\n",
    "        dice_loss_values = torch.stack(dice_loss_values)\n",
    "\n",
    "        # If you want the average loss over the batch to be returned\n",
    "        if self.size_average:\n",
    "            return dice_loss_values.mean()\n",
    "        else:\n",
    "            # If you want individual losses for each sample in the batch\n",
    "            return dice_loss_values\n",
    "\n",
    "def smooth_heaviside(phi, alpha, epsilon):\n",
    "    # Scale and shift phi for the sigmoid function\n",
    "    scaled_phi = (phi - alpha) / epsilon\n",
    "    \n",
    "    # Apply the sigmoid function\n",
    "    H = torch.sigmoid(scaled_phi)\n",
    "\n",
    "    return H\n",
    "def calc_Phi(variable, LSgrid):\n",
    "    device = variable.device  # Get the device of the variable\n",
    "\n",
    "    x0 = variable[0]\n",
    "    y0 = variable[1]\n",
    "    L = variable[2]\n",
    "    t1 = variable[3]\n",
    "    t2 = variable[4]\n",
    "    angle = variable[5]\n",
    "\n",
    "    # Rotation\n",
    "    st = torch.sin(angle)\n",
    "    ct = torch.cos(angle)\n",
    "    x1 = ct * (LSgrid[0][:, None].to(device) - x0) + st * (LSgrid[1][:, None].to(device) - y0) \n",
    "    y1 = -st * (LSgrid[0][:, None].to(device) - x0) + ct * (LSgrid[1][:, None].to(device) - y0)\n",
    "\n",
    "    # Regularized hyperellipse equation\n",
    "    a = L / 2  # Semi-major axis\n",
    "    b = (t1 + t2) / 2  # Semi-minor axis\n",
    "    small_constant = 1e-9  # To avoid division by zero\n",
    "    temp = ((x1 / (a + small_constant))**6) + ((y1 / (b + small_constant))**6)\n",
    "\n",
    "    # # Ensuring the hyperellipse shape\n",
    "    allPhi = 1 - (temp + small_constant)**(1/6)\n",
    "\n",
    "    # # Call Heaviside function with allPhi\n",
    "    alpha = torch.tensor(1e-9, device=device, dtype=torch.float32)\n",
    "    epsilon = torch.tensor(0.02, device=device, dtype=torch.float32)\n",
    "    H_phi = smooth_heaviside(allPhi, alpha, epsilon)\n",
    "    return allPhi, H_phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "\n",
    "norm = TwoSlopeNorm(vmin=-10, vcenter=0, vmax=10)\n",
    "# Load the input image\n",
    "input_image_path = test_path + '.png'\n",
    "input_image = Image.open(input_image_path)\n",
    "input_image = upscaled_image\n",
    "#I want to create a numpy array of the grayscale input image where black is 1 and white is 0:\n",
    "input_image_array = np.array(input_image.convert('L'))\n",
    "# input_image_array is of shape (480,640) and pred_H_resized is of shape (1,1,160,160):\n",
    "# I want to calculate the dice loss between the two:\n",
    "# I first need to resize the input_image_array to 160,160 using  F.interpolate\n",
    "input_image_array_tensor = torch.tensor(input_image_array)\n",
    "\n",
    "resized_input_image_array_tensor = F.interpolate(input_image_array_tensor.unsqueeze(0).unsqueeze(0), size=torch.Size([640,640]), mode='nearest')\n",
    "\n",
    "# Normalize the resized_input_image_array_tensor:\n",
    "resized_input_image_array_tensor = resized_input_image_array_tensor / 255.0\n",
    "\n",
    "#Now the input_image has pixel values of 1.0 for white and 0.0 for black. I need to inverse that:\n",
    "resized_input_image_array_tensor = 1.0 - resized_input_image_array_tensor\n",
    "\n",
    "\n",
    "#I need to flip upside down the resized_input_image_array_tensor:\n",
    "resized_input_image_array_tensor = torch.flip(resized_input_image_array_tensor, [2])\n",
    "# Get the segmentation result\n",
    "for r in results:\n",
    "    im_array = r.plot(boxes=True, labels=False, line_width=1)\n",
    "    seg_result = Image.fromarray(im_array[..., ::-1])\n",
    "\n",
    "\n",
    "\n",
    "DW = 1.0\n",
    "DH = 1.0\n",
    "\n",
    "\n",
    "nelx = int(400 * DW)\n",
    "nely = int(400 * DH)\n",
    "\n",
    "x, y = torch.meshgrid(torch.linspace(0, DW, nelx+1), torch.linspace(0, DH, nely+1))\n",
    "LSgrid = torch.stack((y.flatten(), x.flatten()), dim=0)\n",
    "\n",
    "#xmax = torch.tensor([DW, DH, np.sqrt(DW**2 + DH**2), 0.05 * min(DW, DH), 0.05 * min(DW, DH), np.pi])\n",
    "xmax = torch.tensor([1.0, 1.0, 1.0, 1.0, 0.2, 0.2])\n",
    "\n",
    "xmin = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.01, 0.01])\n",
    "\n",
    "\n",
    "xmax_preds = xmax.unsqueeze(0).expand(prediction_tensor.shape[0],-1) \n",
    "xmin_preds = xmin.unsqueeze(0).expand(prediction_tensor.shape[0],-1)\n",
    "\n",
    "xmax = xmax.unsqueeze(0).expand(8, -1)  \n",
    "xmin = xmin.unsqueeze(0).expand(8, -1) \n",
    "unnormalized_preds = prediction_tensor * (xmax_preds - xmin_preds) + xmin_preds\n",
    "# # # The design variables are infered from the two endpoints and the two thicknesses:\n",
    "x_center = (unnormalized_preds[:, 0] + unnormalized_preds[:, 2]) / 2\n",
    "y_center = (unnormalized_preds[:, 1] + unnormalized_preds[:, 3]) / 2\n",
    "\n",
    "L = torch.sqrt((unnormalized_preds[:, 0] - unnormalized_preds[:, 2])**2 + \n",
    "            (unnormalized_preds[:, 1] - unnormalized_preds[:, 3])**2)\n",
    "\n",
    "L = L+1e-4\n",
    "t_1 = unnormalized_preds[:, 4]\n",
    "t_2 = unnormalized_preds[:, 5]\n",
    "\n",
    "epsilon = 1e-10\n",
    "y_diff = unnormalized_preds[:, 3] - unnormalized_preds[:, 1] + epsilon\n",
    "x_diff = unnormalized_preds[:, 2] - unnormalized_preds[:, 0] + epsilon\n",
    "theta = torch.atan2(y_diff, x_diff)\n",
    "formatted_variables = torch.cat((x_center.unsqueeze(1), \n",
    "                    y_center.unsqueeze(1), \n",
    "                    L.unsqueeze(1), \n",
    "                    t_1.unsqueeze(1), \n",
    "                    t_2.unsqueeze(1), \n",
    "                    theta.unsqueeze(1)), dim=1)\n",
    "\n",
    "pred_Phi,pred_H = calc_Phi(formatted_variables.T,LSgrid)\n",
    "\n",
    "\n",
    "sum_pred_H = torch.sum(pred_H, dim=1)\n",
    "sum_pred_H= torch.reshape(sum_pred_H,(1,1,nely+1,nelx+1))\n",
    "\n",
    "# # Rearrange H_phi to the shape ([batch_size, channels, height, width])\n",
    "# # Use interpolate to resize\n",
    "pred_H_resized = F.interpolate(sum_pred_H, size=torch.Size([640,640]), mode='nearest')\n",
    "\n",
    "diceloss = CustomDiceLoss()\n",
    "pred_H_resized_flipped = torch.flip(pred_H_resized, [2])\n",
    "\n",
    "#threshold both the prediction and the label with 0.5:\n",
    "pred_H_resized_flipped[pred_H_resized_flipped > 0.5] = 1\n",
    "pred_H_resized_flipped[pred_H_resized_flipped <= 0.5] = 0\n",
    "# Calculate the dice loss:\n",
    "dice_loss = diceloss(pred_H_resized_flipped, resized_input_image_array_tensor)\n",
    "\n",
    "\n",
    "# Create a combined 2x2 plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12)) # 2x2 subplot\n",
    "\n",
    "# Top-left: Input image\n",
    "axes[0, 0].imshow(resized_input_image_array_tensor.squeeze(),origin='lower', cmap='gray_r')\n",
    "axes[0, 0].set_title('Input Image')\n",
    "axes[0, 0].axis('on')\n",
    "\n",
    "# Top-right: Segmentation Result\n",
    "axes[0, 1].imshow(seg_result)\n",
    "axes[0, 1].set_title('Segmentation Result')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# # Bottom-right: pred_Phi contour\n",
    "render_colors1 = ['yellow', 'g', 'r', 'c', 'm', 'y', 'black', 'orange', 'pink', 'cyan', 'slategrey', 'wheat', 'purple', 'mediumturquoise', 'darkviolet', 'orangered']\n",
    "for i, color in zip(range(0, pred_Phi.shape[1]), render_colors1*10):\n",
    "    axes[1, 1].contourf(np.flipud(pred_Phi[:, i].reshape((nely+1, nelx+1))), [-0.1,0,1], colors=color)\n",
    "axes[1, 1].set_title('Prediction contours')\n",
    "\n",
    "# Bottom-left: Prediction H\n",
    "axes[1, 0].imshow(pred_H_resized_flipped.squeeze().detach().numpy(), origin='lower', cmap='gray_r')\n",
    "axes[1, 0].set_title('Prediction Projection')\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.01)  # Adjust hspace to reduce vertical space\n",
    "\n",
    "plt.figtext(0.5, 0.05, f'Dice Loss: {dice_loss.item():.4f}', ha='center', fontsize=16)\n",
    "\n",
    "# Save the combined plot\n",
    "fig.savefig('combined_plots.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_image_array is of shape (480,640) and pred_H_resized is of shape (1,1,160,160):\n",
    "# I want to calculate the dice loss between the two:\n",
    "# I first need to resize the input_image_array to 160,160 using  F.interpolate\n",
    "input_image_array_tensor = torch.tensor(input_image_array)\n",
    "\n",
    "\n",
    "resized_input_image_array_tensor = F.interpolate(input_image_array_tensor.unsqueeze(0).unsqueeze(0), size=torch.Size([160,160]), mode='nearest')\n",
    "\n",
    "# Normalize the resized_input_image_array_tensor:\n",
    "resized_input_image_array_tensor = resized_input_image_array_tensor / 255.0\n",
    "\n",
    "#Now the input_image has pixel values of 1.0 for white and 0.0 for black. I need to inverse that:\n",
    "resized_input_image_array_tensor = 1.0 - resized_input_image_array_tensor\n",
    "\n",
    "\n",
    "\n",
    "#I need to flip upside down the resized_input_image_array_tensor:\n",
    "resized_input_image_array_tensor = torch.flip(resized_input_image_array_tensor, [2])\n",
    "# Calculate the dice loss:\n",
    "dice_loss = diceloss(pred_H_resized_flipped, resized_input_image_array_tensor)\n",
    "\n",
    "dice_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Heaviside(phi, alpha, epsilon):\n",
    "    device = phi.device  # Get the device of phi\n",
    "\n",
    "    # For values outside of [-epsilon, epsilon]\n",
    "    H_positive = torch.ones_like(phi, device=device) \n",
    "    H_negative = alpha * torch.ones_like(phi, device=device)\n",
    "\n",
    "    # For values inside [-epsilon, epsilon]\n",
    "    default = 3 * (1 - alpha) / 4 * (phi / epsilon - phi**3 / (3 * epsilon**3)) + (1 + alpha) / 2\n",
    "\n",
    "    # Construct Heavisidve using conditions\n",
    "    H = torch.where(phi > epsilon, H_positive, torch.where(phi < -epsilon, H_negative, default))\n",
    "\n",
    "    return H\n",
    "\n",
    "\n",
    "def smooth_heaviside(phi, alpha, epsilon):\n",
    "    # Scale and shift phi for the sigmoid function\n",
    "    scaled_phi = (phi - alpha) / epsilon\n",
    "    \n",
    "    # Apply the sigmoid function\n",
    "    H = torch.sigmoid(scaled_phi)\n",
    "\n",
    "    return H\n",
    "\n",
    "# def calc_Phi(variable, LSgrid):\n",
    "#     device = variable.device  # Get the device of variable\n",
    "#     alpha = torch.tensor(1e-9, device=device, dtype=torch.float32)\n",
    "#     epsilon = torch.tensor(0.01, device=device, dtype=torch.float32)\n",
    "\n",
    "\n",
    "#     x0 = variable[0]\n",
    "#     y0 = variable[1]\n",
    "#     L = variable[2]\n",
    "#     t1 = variable[3]\n",
    "#     t2 = variable[4]\n",
    "#     angle = variable[5]\n",
    "\n",
    "#     st = torch.sin(angle)\n",
    "#     ct = torch.cos(angle)\n",
    "\n",
    "#     x1 = ct * (LSgrid[0][:, None].to(device) - x0) + st * (LSgrid[1][:, None].to(device) - y0) \n",
    "#     y1 = -st * (LSgrid[0][:, None].to(device) - x0) + ct * (LSgrid[1][:, None].to(device) - y0) \n",
    "#     small_constant = 1e-09  # You can adjust this value\n",
    "#     l = (t1 + t2) / 2 + (t2 - t1) / 2 / L * x1\n",
    "#     temp = ((x1)**6) / ((L**6)) + ((y1)**6) / ((l**6))\n",
    "#     allPhi = 1 - (temp+small_constant)**(1/6)\n",
    "    \n",
    "#     # # Call Heaviside function with allPhi, alpha, and epsilon\n",
    "#     H_phi = smooth_heaviside(allPhi, alpha, epsilon)\n",
    "\n",
    "#     # return allPhi\n",
    "#     return  allPhi, H_phi\n",
    "\n",
    "def calc_Phi(variable, LSgrid):\n",
    "    device = variable.device  # Get the device of the variable\n",
    "\n",
    "    x0 = variable[0]\n",
    "    y0 = variable[1]\n",
    "    L = variable[2]\n",
    "    t1 = variable[3]\n",
    "    t2 = variable[4]\n",
    "    angle = variable[5]\n",
    "\n",
    "    # Rotation\n",
    "    st = torch.sin(angle)\n",
    "    ct = torch.cos(angle)\n",
    "    x1 = ct * (LSgrid[0][:, None].to(device) - x0) + st * (LSgrid[1][:, None].to(device) - y0) \n",
    "    y1 = -st * (LSgrid[0][:, None].to(device) - x0) + ct * (LSgrid[1][:, None].to(device) - y0)\n",
    "\n",
    "    # Regularized hyperellipse equation\n",
    "    a = L / 2  # Semi-major axis\n",
    "    b = (t1 + t2) / 2  # Semi-minor axis\n",
    "    small_constant = 1e-9  # To avoid division by zero\n",
    "    temp = ((x1 / (a + small_constant))**6) + ((y1 / (b + small_constant))**6)\n",
    "\n",
    "    # # Ensuring the hyperellipse shape\n",
    "    allPhi = 1 - (temp + small_constant)**(1/6)\n",
    "\n",
    "    # # Call Heaviside function with allPhi\n",
    "    alpha = torch.tensor(1e-9, device=device, dtype=torch.float32)\n",
    "    epsilon = torch.tensor(0.01, device=device, dtype=torch.float32)\n",
    "    H_phi = smooth_heaviside(allPhi, alpha, epsilon)\n",
    "    return allPhi, H_phi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import gradcheck\n",
    "import numpy as np\n",
    "# Your calc_Phi function here\n",
    "\n",
    "# Preparing the grid as in your example\n",
    "DW = 1.0\n",
    "DH = 1.0\n",
    "nelx = int(400 * DW)\n",
    "nely = int(400 * DH)\n",
    "x, y = torch.meshgrid(torch.linspace(0, DW, nelx+1), torch.linspace(0, DH, nely+1), indexing='xy')\n",
    "LSgrid = torch.stack((y.flatten(), x.flatten()), dim=0).to(torch.float64)\n",
    "\n",
    "# Ensure the test_tensor and p require gradients\n",
    "test_tensor = torch.tensor([0.5, 0.5, 1.0, 1.0, 0.0, 0.0], requires_grad=True,dtype=torch.float64).unsqueeze(0)\n",
    "\n",
    "\n",
    "# xmax = torch.tensor([1.0, 1.0, 0.75, 0.2, 0.2, np.pi])\n",
    "\n",
    "# xmin = torch.tensor([0.0, 0.0, 0.01, 0.01, 0.00, 0.0])\n",
    "\n",
    "xmax = torch.tensor([1.0, 1.0, 1.0, 1.0, 0.2, 0.2])\n",
    "\n",
    "xmin = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.01, 0.01])\n",
    "\n",
    "unnormalized_preds = test_tensor * (xmax - xmin) + xmin\n",
    "# The design variables are infered from the two endpoints and the two thicknesses:\n",
    "x_center = (unnormalized_preds[:, 0] + unnormalized_preds[:, 2]) / 2\n",
    "y_center = (unnormalized_preds[:, 1] + unnormalized_preds[:, 3]) / 2\n",
    "\n",
    "def safe_sqrt(x, eps=1e-6):\n",
    "    return torch.sqrt(x + eps)\n",
    "\n",
    "L = safe_sqrt((unnormalized_preds[:, 0] - unnormalized_preds[:, 2])**2 + \n",
    "            (unnormalized_preds[:, 1] - unnormalized_preds[:, 3])**2)\n",
    "\n",
    "# gradcheck_result = gradcheck(safe_sqrt, ((unnormalized_preds[:, 0] - unnormalized_preds[:, 2])**2 + \n",
    "#             (unnormalized_preds[:, 1] - unnormalized_preds[:, 3])**2))\n",
    "# print(\"Gradcheck passed:\", gradcheck_result)\n",
    "\n",
    "L = L+1e-4\n",
    "t_1 = unnormalized_preds[:, 4]\n",
    "t_2 = unnormalized_preds[:, 5]\n",
    "\n",
    "y_diff = unnormalized_preds[:, 3] - unnormalized_preds[:, 1] \n",
    "x_diff = unnormalized_preds[:, 2] - unnormalized_preds[:, 0] \n",
    "theta = torch.atan2(y_diff, x_diff)\n",
    "\n",
    "formatted_variables = torch.cat((x_center.unsqueeze(1), \n",
    "                    y_center.unsqueeze(1), \n",
    "                    L.unsqueeze(1), \n",
    "                    t_1.unsqueeze(1), \n",
    "                    t_2.unsqueeze(1), \n",
    "                    theta.unsqueeze(1)), dim=1)\n",
    "# # # # # # # Call gradcheck\n",
    "# gradcheck_result = gradcheck(calc_Phi, (unnormalized_preds.T, LSgrid))\n",
    "\n",
    "# print(\"Gradcheck passed:\", gradcheck_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(unnormalized_preds)\n",
    "# pred_Phi, H_phi = calc_Phi(unnormalized_preds.T, LSgrid)\n",
    "pred_phi, H_phi = calc_Phi(formatted_variables.T, LSgrid)\n",
    "\n",
    "H_phi = H_phi.detach()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Calculate the sigmoid function of H_phi:\n",
    "#sigmoid = 1/(1+np.exp(-H_phi))\n",
    "# Plot the sigmoid function\n",
    "plt.imshow(H_phi.detach().reshape((nely+1, nelx+1)), cmap='viridis', origin='lower')\n",
    "plt.colorbar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "DW = 1.0\n",
    "DH = 1.0\n",
    "\n",
    "test_tensor = torch.tensor([0.5, 0.5, 0.5, 1.0, 1.0, 1.0]).unsqueeze(0)\n",
    "nelx = int(200 * DW)\n",
    "nely = int(200 * DH)\n",
    "\n",
    "x, y = torch.meshgrid(torch.linspace(0, DW, nelx+1), torch.linspace(0, DH, nely+1))\n",
    "LSgrid = torch.stack((y.flatten(), x.flatten()), dim=0)\n",
    "\n",
    "#xmax = torch.tensor([DW, DH, np.sqrt(DW**2 + DH**2), 0.05 * min(DW, DH), 0.05 * min(DW, DH), np.pi])\n",
    "xmax = torch.tensor([1.0, 1.0, 0.75, 0.05, 0.05, np.pi])\n",
    "\n",
    "xmin = torch.tensor([0.0, 0.0, 0.001, 0.0, 0.0, 0.0])\n",
    "\n",
    "\n",
    "\n",
    "xmax_preds = xmax.unsqueeze(0).expand(test_tensor.shape[0],-1) \n",
    "xmin_preds = xmin.unsqueeze(0).expand(test_tensor.shape[0],-1)\n",
    "\n",
    "xmax = xmax.unsqueeze(0).expand(8, -1)  \n",
    "xmin = xmin.unsqueeze(0).expand(8, -1) \n",
    "\n",
    "unnormalized_preds = test_tensor * (xmax_preds - xmin_preds) + xmin_preds\n",
    "\n",
    "\n",
    "pred_Phi,pred_H = calc_Phi(unnormalized_preds.T,LSgrid,6,epsilon=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(pred_H.reshape(201,201).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to scale pred_Phi[:,0] to [0,1] and then plot it:\n",
    "normalized = (pred_Phi[:,0] - pred_Phi[:,0].min()) / (pred_Phi[:,0].max() - pred_Phi[:,0].min())\n",
    "\n",
    "plt.imshow((normalized>0.9).reshape((nely+1, nelx+1)))\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(normalized.reshape(201,201), pred_H.reshape(201,201))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming pred_Phi is defined somewhere in your code\n",
    "# normalized = (pred_Phi[:,2] - pred_Phi[:,2].min()) / (pred_Phi[:,2].max() - pred_Phi[:,2].min())\n",
    "\n",
    "# Create a meshgrid for plotting\n",
    "x = np.linspace(0, 1, nelx+1)\n",
    "y = np.linspace(0, 1, nely+1)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Create a figure and 3D axis\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the surface\n",
    "surf = ax.plot_surface(X, Y, np.minimum(pred_Phi[:,1],0.0).reshape((nely+1, nelx+1)), cmap='viridis')\n",
    "\n",
    "# Add colorbar\n",
    "fig.colorbar(surf)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you've defined and normalized your data as before...\n",
    "\n",
    "\n",
    "\n",
    "# Create the 3D surface plot\n",
    "fig = go.Figure(data=[go.Surface(z=np.minimum(pred_Phi[:,2],0.0).reshape((nely+1, nelx+1)), x=X, y=Y, colorscale='viridis')])\n",
    "\n",
    "fig.update_layout(title='3D Surface Plot', scene=dict(zaxis=dict(range=[-10,1])),height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming pred_H_resized_flipped and label_H_resized are thresholded to contain values 0 or 1.\n",
    "\n",
    "# 1. Compute the intersection\n",
    "intersection = pred_H_resized_flipped * label_H_resized\n",
    "\n",
    "# 2. Plot the original images and their intersection\n",
    "\n",
    "# Create a combined 3x1 plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 12)) # 3x1 subplot to account for colorbars\n",
    "\n",
    "# Left: label_H_resized\n",
    "im0 = axes[0].imshow(label_H_resized[0,0,:,:], origin='lower')\n",
    "axes[0].set_title('Ground Truth')\n",
    "#fig.colorbar(im0, ax=axes[0])\n",
    "\n",
    "# Middle: pred_H_resized_flipped\n",
    "im1 = axes[1].imshow(pred_H_resized_flipped[0,0,:,:], origin='lower')\n",
    "axes[1].set_title('Prediction')\n",
    "#fig.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# Right: Intersection\n",
    "im2 = axes[2].imshow(intersection[0,0,:,:], origin='lower')\n",
    "axes[2].set_title('Intersection')\n",
    "#fig.colorbar(im2, ax=axes[2])\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the input image\n",
    "input_image_path = test_path + '.png'\n",
    "input_image = Image.open(input_image_path)\n",
    "\n",
    "# Get the segmentation result\n",
    "results = model(input_image_path, conf=0.25)\n",
    "for r in results:\n",
    "    im_array = r.plot(boxes=True, labels=False, line_width=1)\n",
    "    seg_result = Image.fromarray(im_array[..., ::-1])\n",
    "\n",
    "# Create a combined 1x2 plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # 1x2 subplot\n",
    "\n",
    "# Left: Input image\n",
    "axes[0].imshow(input_image)\n",
    "axes[0].set_title('Input Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Right: Segmentation Result\n",
    "axes[1].imshow(seg_result)\n",
    "axes[1].set_title('Segmentation Result')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customyolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
